{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8d9f3dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex im_path = ONLY the base dir: /images\n",
      "ex label_path_list = all category dirs eg images/ramen/\n",
      "ex img_path_list = all .jpg files eg images/ramen/125235.jpg\n",
      "ex class_list = ['spring_rolls', 'pulled_pork_sandwich',...]\n"
     ]
    }
   ],
   "source": [
    "#   NOTEBOOK STRUCTURE:\n",
    "# STEP 0: imports and TRAIN/TEST BEHAVIOR\n",
    "# 0.1: Train step\n",
    "# 0.2: Test step\n",
    "# 0.3: Loop\n",
    "# STEP 1: DATA\n",
    "# 1.1: Paths lists, validate?\n",
    "# 1.2: Transforms, dataloaders \n",
    "# STEP 2: ARCHITECTURE\n",
    "# STEP 3: Training loop\n",
    "# STEP 4: ANALYSIS\n",
    "# STEP 5: EXPORT\n",
    "\n",
    "def reminder():\n",
    "    '''Prints a series of reminder text about global variables and their contents'''\n",
    "    print(\"ex im_path = ONLY the base dir: /images\")\n",
    "    print(\"ex label_path_list = all category dirs eg images/ramen/\")\n",
    "    print(\"ex img_path_list = all .jpg files eg images/ramen/125235.jpg\")\n",
    "    print(\"ex class_list = ['spring_rolls', 'pulled_pork_sandwich',...]\")\n",
    "\n",
    "reminder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eba60955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 0: Imports, init cuda\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "torch.__version__\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9c5b7c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1: Train step\n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer):\n",
    "  model.train() # train mode\n",
    "\n",
    "  train_loss, train_acc = 0, 0\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    # Backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Accuracy\n",
    "    y_pred_class = torch.argmax(y_pred, dim=1)\n",
    "    train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "  # Compute average loss and accuracy\n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader)\n",
    "  return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b150960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2: Test step\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module):\n",
    "  model.eval() # eval mode\n",
    "\n",
    "  test_loss, test_acc = 0, 0\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "      X, y = X.to(device), y.to(device)\n",
    "      # forward pass\n",
    "      test_pred_logits = model(X)\n",
    "      # calculate the loss\n",
    "      loss = loss_fn(test_pred_logits, y)\n",
    "      test_loss += loss.item()\n",
    "      # calc acc\n",
    "      test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "      test_acc += ((test_pred_labels==y)).sum().item()/len(test_pred_labels)\n",
    "\n",
    "  # Compute average loss and accuracy\n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "51616690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.3: Loop\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_loop(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int):\n",
    "\n",
    "    # create empty results dictionary\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    # loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
    "        results[\"train_acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
    "        results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
    "        results[\"test_acc\"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "71c48308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\zecer\\.cache\\kagglehub\\datasets\\oddrationale\\mnist-in-csv\\versions\\2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0          5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1          0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2          4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3          1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4          9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "59995      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59996      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59997      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59998      6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59999      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0          0      0      0      0      0      0      0      0  \n",
       "1          0      0      0      0      0      0      0      0  \n",
       "2          0      0      0      0      0      0      0      0  \n",
       "3          0      0      0      0      0      0      0      0  \n",
       "4          0      0      0      0      0      0      0      0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "59995      0      0      0      0      0      0      0      0  \n",
       "59996      0      0      0      0      0      0      0      0  \n",
       "59997      0      0      0      0      0      0      0      0  \n",
       "59998      0      0      0      0      0      0      0      0  \n",
       "59999      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[60000 rows x 785 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1: DATA\n",
    "# 1.1: Paths lists, validate\n",
    "\n",
    "# Download latest version of data from kaggle \n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"oddrationale/mnist-in-csv\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "df = pd.read_csv(path + '/mnist_train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e3beeabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2: Transforms, train-test-split, dataloaders \n",
    "\n",
    "# load data into numpy vectors with test_train_split\n",
    "y = df['label'].values\n",
    "X = df.drop(columns=['label'],axis=1).values.astype('float32')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# define transform\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# convert data and labels to torch vectors\n",
    "torch_X_train = torch.from_numpy(X_train).type(torch.float32).view(-1, 1, 28, 28).to(device)\n",
    "torch_y_train = torch.from_numpy(y_train).type(torch.long).to(device)\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "torch_X_test = torch.from_numpy(X_test).type(torch.float32).view(-1, 1, 28, 28).to(device)\n",
    "torch_y_test = torch.from_numpy(y_test).type(torch.long).to(device)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f7066b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 2: ARCHITECTURE\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)  # 28x28 -> 26x26\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1) # 26x26 -> 24x24\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128)  # After 2x2 pooling\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))       # 28 -> 26\n",
    "        x = F.relu(self.conv2(x))       # 26 -> 24\n",
    "        x = F.max_pool2d(x, 2)          # 24 -> 12\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)         # flatten except batch dim\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CNN().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8c167ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outp logits: tensor([[ 7.0822, -5.9170, -3.8916, -6.5120, -4.0127, -5.5917, -0.1559,  4.9961,\n",
      "         -4.9308,  8.4320]], device='cuda:0'),\n",
      " outp probabilities: tensor([[2.0075e-01, 4.5411e-07, 3.4416e-06, 2.5046e-07, 3.0491e-06, 6.2871e-07,\n",
      "         1.4427e-04, 2.4926e-02, 1.2174e-06, 7.7418e-01]], device='cuda:0')\n",
      "outp label: tensor([9], device='cuda:0')\n",
      " actual label: 0\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Loss fn, optimizer, dummy forward pass\n",
    "\n",
    "# reasonably good choices depend on data\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# dummy forward pass\n",
    "batch, label_batch = next(iter(train_loader))\n",
    "img, label = batch[0].unsqueeze(dim=0), label_batch[0] \n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "  pred = model(img.to(device))\n",
    "\n",
    "print(f'outp logits: {pred},\\n outp probabilities: {torch.softmax(pred, dim=1)}')\n",
    "print(f'outp label: {torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n actual label: {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "85c592fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48584dcc51e64a86bffa0b9c8446c0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.3637 | train_acc: 0.9421 | test_loss: 0.0645 | test_acc: 0.9791\n",
      "Epoch: 2 | train_loss: 0.0726 | train_acc: 0.9775 | test_loss: 0.0653 | test_acc: 0.9808\n",
      "Epoch: 3 | train_loss: 0.0528 | train_acc: 0.9834 | test_loss: 0.0548 | test_acc: 0.9831\n",
      "Epoch: 4 | train_loss: 0.0449 | train_acc: 0.9862 | test_loss: 0.0586 | test_acc: 0.9840\n",
      "Epoch: 5 | train_loss: 0.0386 | train_acc: 0.9880 | test_loss: 0.0505 | test_acc: 0.9862\n",
      "Total training time: 8.016 seconds\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Training loop\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "start_time = timer()\n",
    "\n",
    "# Training begins here\n",
    "NUM_EPOCHS = 5\n",
    "model_results = train_loop(model=model,\n",
    "                        train_dataloader=train_loader,\n",
    "                        test_dataloader=test_loader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn,\n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0a0cb22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG CELL (type whatever in here)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b5610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: ANALYSIS\n",
    "def plot_loss_curves(results):\n",
    "  loss = results['train_loss']\n",
    "  test_loss = results['test_loss']\n",
    "\n",
    "  acc = results['train_acc']\n",
    "  test_acc = results['test_acc']\n",
    "\n",
    "  epochs = range(len(results['train_loss']))\n",
    "\n",
    "  plt.plot(epochs, loss, label='train_loss')\n",
    "  plt.plot(epochs, test_loss, label='test_loss')\n",
    "  plt.title('Loss')\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf33dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 5: EXPORT\n",
    "\n",
    "# save and load as pytorch file (.pt) INFERENCE ONLY\n",
    "pt_path = 'model.pt'\n",
    "torch.save(model.state_dict(), pt_path)\n",
    "model = CNN() # match correct model architecture\n",
    "model.load_state_dict(torch.load(pt_path, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6107e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zecer\\AppData\\Local\\Temp\\ipykernel_3384\\1829845849.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pt_model.load_state_dict(torch.load(pt_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `CNN([...]` with `torch.export.export`...\n",
      "[torch.onnx] Obtain model graph for `CNN([...]` with `torch.export.export`... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=9,\n",
       "            opset_imports={'': 18, 'pkg.onnxscript.torch_lib.common': 1},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.5.1+cu121',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"x\"<FLOAT,[1,1,28,28]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"addmm_1\"<FLOAT,[1,10]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"conv1.weight\"<FLOAT,[32,1,3,3]>{TorchTensor(...)},\n",
       "                %\"conv1.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"conv2.weight\"<FLOAT,[64,32,3,3]>{TorchTensor(...)},\n",
       "                %\"conv2.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"fc1.weight\"<FLOAT,[128,9216]>{TorchTensor(...)},\n",
       "                %\"fc1.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
       "                %\"fc2.weight\"<FLOAT,[10,128]>{TorchTensor(...)},\n",
       "                %\"fc2.bias\"<FLOAT,[10]>{TorchTensor<FLOAT,[10]>(Parameter containing: tensor([ 0.0680, -0.0497, -0.0166,  0.0536,  0.0370,  0.0259,  0.0291,  0.0698, 0.1111,  0.0585], requires_grad=True), name='fc2.bias')}\n",
       "            ),\n",
       "        ) {\n",
       "             0 |  # node_Conv_0\n",
       "                  %\"convolution\"<FLOAT,[1,32,26,26]> ⬅️ ::Conv(%\"x\", %\"conv1.weight\"{...}, %\"conv1.bias\"{...}) {group=1, auto_pad=NOTSET, dilations=[1, 1], strides=[1, 1], pads=[0, 0, 0, 0]}\n",
       "             1 |  # node_Relu_1\n",
       "                  %\"relu\"<FLOAT,[1,32,26,26]> ⬅️ ::Relu(%\"convolution\")\n",
       "             2 |  # node_Conv_2\n",
       "                  %\"convolution_1\"<FLOAT,[1,64,24,24]> ⬅️ ::Conv(%\"relu\", %\"conv2.weight\"{...}, %\"conv2.bias\"{...}) {group=1, auto_pad=NOTSET, dilations=[1, 1], strides=[1, 1], pads=[0, 0, 0, 0]}\n",
       "             3 |  # node_Relu_3\n",
       "                  %\"relu_1\"<FLOAT,[1,64,24,24]> ⬅️ ::Relu(%\"convolution_1\")\n",
       "             4 |  # node_MaxPool_4\n",
       "                  %\"getitem\"<FLOAT,[1,64,12,12]>, %\"val_0\"<?,?> ⬅️ ::MaxPool(%\"relu_1\") {kernel_shape=[2, 2], strides=[2, 2], dilations=(1, 1), auto_pad=NOTSET, pads=(0, 0, 0, 0), ceil_mode=False, storage_order=0}\n",
       "             5 |  # node_MaxPool_5\n",
       "                  %\"val_1\"<?,?>, %\"val_2\"<?,?> ⬅️ ::MaxPool(%\"relu_1\") {kernel_shape=[1, 1], strides=[1, 1], dilations=(1, 1), auto_pad=NOTSET, ceil_mode=0, storage_order=0}\n",
       "             6 |  # node_Constant_6\n",
       "                  %\"val_3\"<?,?> ⬅️ ::Constant() {value_ints=[1, 1]}\n",
       "             7 |  # node_Constant_7\n",
       "                  %\"val_4\"<?,?> ⬅️ ::Constant() {value_ints=[0, 0]}\n",
       "             8 |  # node_Constant_8\n",
       "                  %\"val_5\"<?,?> ⬅️ ::Constant() {value_ints=[2, 3]}\n",
       "             9 |  # node_Slice_9\n",
       "                  %\"val_6\"<?,?> ⬅️ ::Slice(%\"val_2\", %\"val_4\", %\"val_3\", %\"val_5\")\n",
       "            10 |  # node_Sub_10\n",
       "                  %\"max_pool2d_with_indices__1\"<INT64,[1,64,12,12]> ⬅️ ::Sub(%\"val_0\", %\"val_6\")\n",
       "            11 |  # node_Identity_11\n",
       "                  %\"clone\"<FLOAT,[1,64,12,12]> ⬅️ ::Identity(%\"getitem\")\n",
       "            12 |  # node_Constant_12\n",
       "                  %\"val_7\"<?,?> ⬅️ ::Constant() {value=Tensor<INT64,[2]>(array([   1, 9216], dtype=int64), name=None)}\n",
       "            13 |  # node_Cast_13\n",
       "                  %\"val_8\"<?,?> ⬅️ ::Cast(%\"val_7\") {to=INT64}\n",
       "            14 |  # node_Reshape_14\n",
       "                  %\"view\"<FLOAT,[1,9216]> ⬅️ ::Reshape(%\"clone\", %\"val_8\") {allowzero=True}\n",
       "            15 |  # node_Transpose_15\n",
       "                  %\"t\"<FLOAT,[9216,128]> ⬅️ ::Transpose(%\"fc1.weight\"{...}) {perm=[1, 0]}\n",
       "            16 |  # node_Gemm_16\n",
       "                  %\"addmm\"<FLOAT,[1,128]> ⬅️ ::Gemm(%\"view\", %\"t\", %\"fc1.bias\"{...}) {transA=0, transB=0, alpha=1.0, beta=1.0}\n",
       "            17 |  # node_Relu_17\n",
       "                  %\"relu_2\"<FLOAT,[1,128]> ⬅️ ::Relu(%\"addmm\")\n",
       "            18 |  # node_Transpose_18\n",
       "                  %\"t_1\"<FLOAT,[128,10]> ⬅️ ::Transpose(%\"fc2.weight\"{...}) {perm=[1, 0]}\n",
       "            19 |  # node_Gemm_19\n",
       "                  %\"addmm_1\"<FLOAT,[1,10]> ⬅️ ::Gemm(%\"relu_2\", %\"t_1\", %\"fc2.bias\"{[0.0680144652724266, -0.04966583102941513, -0.016646264120936394, 0.0536157451570034, 0.036963336169719696, 0.025916315615177155, 0.02911876142024994, 0.06981964409351349, 0.11113899201154709, 0.05849991366267204]}) {transA=0, transB=0, alpha=1.0, beta=1.0}\n",
       "            return %\"addmm_1\"<FLOAT,[1,10]>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib.common::Rank(\n",
       "            inputs=(\n",
       "                %\"input\"<?,?>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"tmp\"<?,?> ⬅️ ::Shape(%\"input\")\n",
       "            1 |  # n1\n",
       "                 %\"return_val\"<?,?> ⬅️ ::Size(%\"tmp\")\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib.common::IsScalar(\n",
       "            inputs=(\n",
       "                %\"input\"<?,?>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"tmp\"<?,?> ⬅️ ::Shape(%\"input\")\n",
       "            1 |  # n1\n",
       "                 %\"tmp_0\"<?,?> ⬅️ ::Size(%\"tmp\")\n",
       "            2 |  # n2\n",
       "                 %\"tmp_1\"<?,?> ⬅️ ::Constant() {value_int=0}\n",
       "            3 |  # n3\n",
       "                 %\"return_val\"<?,?> ⬅️ ::Equal(%\"tmp_0\", %\"tmp_1\")\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_conv1_weight: \"f32[32, 1, 3, 3]\", p_conv1_bias: \"f32[32]\", p_conv2_weight: \"f32[64, 32, 3, 3]\", p_conv2_bias: \"f32[64]\", p_fc1_weight: \"f32[128, 9216]\", p_fc1_bias: \"f32[128]\", p_fc2_weight: \"f32[10, 128]\", p_fc2_bias: \"f32[10]\", x: \"f32[1, 1, 28, 28]\"):\n",
       "                     # File: C:\\Users\\zecer\\AppData\\Local\\Temp\\ipykernel_3384\\3854938886.py:12 in forward, code: x = F.relu(self.conv1(x))       # 28 -> 26\n",
       "                    convolution: \"f32[1, 32, 26, 26]\" = torch.ops.aten.convolution.default(x, p_conv1_weight, p_conv1_bias, [1, 1], [0, 0], [1, 1], False, [0, 0], 1);  x = p_conv1_weight = p_conv1_bias = None\n",
       "                    relu: \"f32[1, 32, 26, 26]\" = torch.ops.aten.relu.default(convolution);  convolution = None\n",
       "            \n",
       "                     # File: C:\\Users\\zecer\\AppData\\Local\\Temp\\ipykernel_3384\\3854938886.py:13 in forward, code: x = F.relu(self.conv2(x))       # 26 -> 24\n",
       "                    convolution_1: \"f32[1, 64, 24, 24]\" = torch.ops.aten.convolution.default(relu, p_conv2_weight, p_conv2_bias, [1, 1], [0, 0], [1, 1], False, [0, 0], 1);  relu = p_conv2_weight = p_conv2_bias = None\n",
       "                    relu_1: \"f32[1, 64, 24, 24]\" = torch.ops.aten.relu.default(convolution_1);  convolution_1 = None\n",
       "            \n",
       "                     # File: C:\\Users\\zecer\\AppData\\Local\\Temp\\ipykernel_3384\\3854938886.py:14 in forward, code: x = F.max_pool2d(x, 2)          # 24 -> 12\n",
       "                    max_pool2d_with_indices = torch.ops.aten.max_pool2d_with_indices.default(relu_1, [2, 2]);  relu_1 = None\n",
       "                    getitem: \"f32[1, 64, 12, 12]\" = max_pool2d_with_indices[0];  max_pool2d_with_indices = None\n",
       "            \n",
       "                     # File: C:\\Users\\zecer\\AppData\\Local\\Temp\\ipykernel_3384\\3854938886.py:15 in forward, code: x = self.dropout1(x)\n",
       "                    clone: \"f32[1, 64, 12, 12]\" = torch.ops.aten.clone.default(getitem);  getitem = None\n",
       "            \n",
       "                     # File: C:\\Users\\zecer\\AppData\\Local\\Temp\\ipykernel_3384\\3854938886.py:16 in forward, code: x = torch.flatten(x, 1)         # flatten except batch dim\n",
       "                    view: \"f32[1, 9216]\" = torch.ops.aten.view.default(clone, [1, 9216]);  clone = None\n",
       "            \n",
       "                     # File: C:\\Users\\zecer\\AppData\\Local\\Temp\\ipykernel_3384\\3854938886.py:17 in forward, code: x = F.relu(self.fc1(x))\n",
       "                    t: \"f32[9216, 128]\" = torch.ops.aten.t.default(p_fc1_weight);  p_fc1_weight = None\n",
       "                    addmm: \"f32[1, 128]\" = torch.ops.aten.addmm.default(p_fc1_bias, view, t);  p_fc1_bias = view = t = None\n",
       "                    relu_2: \"f32[1, 128]\" = torch.ops.aten.relu.default(addmm);  addmm = None\n",
       "            \n",
       "                     # File: C:\\Users\\zecer\\AppData\\Local\\Temp\\ipykernel_3384\\3854938886.py:18 in forward, code: x = self.fc2(x)\n",
       "                    t_1: \"f32[128, 10]\" = torch.ops.aten.t.default(p_fc2_weight);  p_fc2_weight = None\n",
       "                    addmm_1: \"f32[1, 10]\" = torch.ops.aten.addmm.default(p_fc2_bias, relu_2, t_1);  p_fc2_bias = relu_2 = t_1 = None\n",
       "                    return (addmm_1,)\n",
       "            \n",
       "        Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_conv1_weight'), target='conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_conv1_bias'), target='conv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_conv2_weight'), target='conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_conv2_bias'), target='conv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_fc1_weight'), target='fc1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_fc1_bias'), target='fc1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_fc2_weight'), target='fc2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_fc2_bias'), target='fc2.bias', persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='addmm_1'), target=None)])\n",
       "        Range constraints: {}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and export as .onnx file INFERENCE ONLY\n",
    "\n",
    "pt_model = CNN() # match correct model architecture\n",
    "pt_model.load_state_dict(torch.load(pt_path))\n",
    "pt_model.eval()\n",
    "ex_input = (torch.zeros(1, 1, 28, 28)) # match correct input dimenstions\n",
    "torch.onnx.export(pt_model, ex_input, 'onnx_model.onnx',\n",
    "                  dtype=torch.float32, dynamo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629959d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b3f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b8df1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b4bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac0e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a9d6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478dbebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
